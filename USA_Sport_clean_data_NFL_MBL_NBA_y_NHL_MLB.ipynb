{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "etc_identifier": "653a3605-5bda-4e1f-beef-04a0173d3f41",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "60da2e57814a61cf6a81dd670bf35473",
          "grade": false,
          "grade_id": "cell-a6c4f74309fc2379",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "5G3JnaGI3DQn"
      },
      "source": [
        "\n",
        "# USA-Sport-clean-data-NFL-MBL-NBA-y-NHL-MLB\n",
        "## Description\n",
        "In this script, we will read a file containing metropolitan regions and their associated sports teams from assets/wikipedia_data.html to answer some questions about each metropolitan area. These regions may have one or more teams from the \"Big 4\" leagues: NFL (football, found in assets/nfl.csv), MLB (baseball, found in assets/mlb.csv), NBA (basketball, found in assets/nba.csv), or NHL (hockey, found in assets/nhl.csv). Remember, all questions should be addressed from the perspective of the metropolitan region, and this file serves as the \"authority\" for the location of each sports team. Thus, teams commonly known by a different area (e.g., \"Oakland Raiders\") need to be mapped to the given metropolitan region (e.g., San Francisco Bay Area).\n",
        "\n",
        "For each sport, please answer the following question: what is the correlation between the win/loss ratio and the population of the city it is in? The win/loss ratio is defined as the number of wins divided by the sum of wins and losses. To calculate the correlation using [pearsonr], you will need to provide two ordered lists of values: the populations from the wikipedia_data.html file and the win/loss ratios for a given sport in the same order. Average the win/loss ratios for cities with multiple teams in a single sport. Each sport contributes equally to this assignment (20%*4=80%) of the total grade. Use only data from the year 2018 for your analysis -- this is crucial!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "v"
      ],
      "metadata": {
        "id": "WtuLOB3z3WXm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "369ff9ecf0ee04640574205cbc697f94",
          "grade": false,
          "grade_id": "cell-712b2b5da63d4505",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "ucGLNfaj3DQq"
      },
      "source": [
        "## Stage 1\n",
        "Win/loss ratio's correlation with the population of the city it is in for the **NHL** using **2018** data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1cac4803b02502929f5b1612d48db2b5",
          "grade": false,
          "grade_id": "cell-69b16e4386e58030",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "qolRglzH3DQq",
        "outputId": "886d4e98-7779-422c-b279-da165ae6d590"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.01230899645574427"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "def nhl_correlation():\n",
        "\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import scipy.stats as stats\n",
        "    import re\n",
        "\n",
        "    nhl_df=pd.read_csv(\"assets/nhl.csv\")\n",
        "    cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
        "    cities=cities.iloc[:-1,[0,3,5,6,7,8]] #Selecciona todas las filas exepto la ultima, y se indica los índices de las columnas que se van a conservar\n",
        "\n",
        "\n",
        "\n",
        "    nhl_df=nhl_df[nhl_df.year==2018] #Dejar solo las columnas del 2018\n",
        "    nhl_df=nhl_df[[\"team\", \"W\", \"L\"]] #Dejar solo las columnas necesarias de NHL\n",
        "    nhl_df[\"team\"] = nhl_df[\"team\"].str.replace(\"\\*$\", \"\", regex=True) #Limpiar el nombre de los equipos. Algunos equipos tienen \"*\" al final\n",
        "    cities[\"NHL\"]=cities[\"NHL\"].replace(r\"\\[.*\\]\", \"\", regex=True) #Limpiar el nombre de los equipos en \"cities\" de \"NHL\". Algunos de ellos tienen \"[]\" en el\n",
        "    cities=cities[['Metropolitan area', 'Population (2016 est.)[8]', 'NHL']] #Eliminar las columnas inecesarias\n",
        "    nhl_df[\"team_only\"] = nhl_df.team.apply(lambda x: x.rsplit(None, 1)[-1]) #En nhl_df los nombres de los equipos están mezclados con los nombres de las ciudades. Cepararlos para obtener los ganadores y perdedores\n",
        "    nhl_df.loc[3, \"team_only\"] = \"Maple Leafs\" #Algunos equipos tienen mas de una palabra en el nombre. Corregir eso\n",
        "    nhl_df.loc[5, \"team_only\"] = \"Red Wings\"\n",
        "    nhl_df.loc[13, \"team_only\"] = \"Blue Jackets\"\n",
        "    nhl_df.loc[27, \"team_only\"] = \"Golden Knights\"\n",
        "\n",
        "    #Remplazar los nombres de los equipos de la misma ciudad\n",
        "\n",
        "    nhl_df.loc[14, \"team_only\"] = \"Rangers Islanders Devils\"\n",
        "    nhl_df.loc[16, \"team_only\"] = \"Rangers Islanders Devils\"\n",
        "    nhl_df.loc[17, \"team_only\"] = \"Rangers Islanders Devils\"\n",
        "\n",
        "    nhl_df.loc[28, \"team_only\"] = \"Kings Ducks\"\n",
        "    nhl_df.loc[30, \"team_only\"] = \"Kings Ducks\"\n",
        "\n",
        "    cities=cities.rename(columns={'Metropolitan area':'city', 'Population (2016 est.)[8]':'population', 'NHL':'team_only'})#Renombrar las ciudades en un formato mas legible\n",
        "    nhl_df=nhl_df[~nhl_df.W.str.contains(\"Division\")]#Quitar las filas inecesarias con el nombre \"Division\" en ellas\n",
        "    nhl_df.W=nhl_df.W.astype(float) #Cambiar el tipo de datos de ganadores y perdedores de str a float\n",
        "    nhl_df.L=nhl_df.L.astype(float)\n",
        "    nhl_df=nhl_df.groupby(by=\"team_only\")[\"W\", \"L\"].mean() #Hay 4 equipos con el mismo nombre, vamos a agruparlos y obtener su promedio de los valores win y lose\n",
        "    nhl_df=nhl_df.reset_index() #Restablecer los indices luego de agruparlos para que puedan ser combinados con cities_df con su columna en común\n",
        "    merged_df=pd.merge(nhl_df, cities, on=\"team_only\") #Combinar ambos dataframes con las columnas requeridas de ambos\n",
        "\n",
        "\n",
        "\n",
        "    merged_df[[\"W\", \"L\"]]=merged_df[[\"W\", \"L\"]].astype(float) #Cambiar el tipo de datos de w y l de str a float\n",
        "\n",
        "\n",
        "\n",
        "    merged_df[\"win_lose_ratio\"] = merged_df.W/(merged_df.L+merged_df.W) #Crear la coluumna ratio win/lose ratio = win/lose+win\n",
        "\n",
        "    #Finalmente pase los valores numericos de population_by_region y win_loss_by_region\n",
        "\n",
        "\n",
        "    population_by_region = pd.to_numeric(merged_df[\"population\"],errors=\"coerce\") # pass in metropolitan area population from cities\n",
        "    win_loss_by_region = pd.to_numeric(merged_df[\"win_lose_ratio\"],errors=\"coerce\") # pass in win/loss ratio from nhl_df in the same order as cities[\"Metropolitan area\"]\n",
        "\n",
        "    assert len(population_by_region) == len(win_loss_by_region), \"Q1: Your lists must be the same length\"\n",
        "    assert len(population_by_region) == 28, \"Q1: There should be 28 teams being analysed for NHL\"\n",
        "\n",
        "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n",
        "nhl_correlation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "988912cae4968d81473f46d783e79c16",
          "grade": false,
          "grade_id": "cell-cb964e690298b71d",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "Qiem6vsG3DQt"
      },
      "source": [
        "## Stage 2\n",
        "Win/loss ratio's correlation with the population of the city it is in for the **NBA** using **2018** data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9394222aafc8ccab0a228098ba0d6010",
          "grade": false,
          "grade_id": "cell-5a5f21279e3d3572",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "jT53mTK13DQt",
        "outputId": "bf4fd304-8ffe-41dc-c204-05f624ad02bb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'assets/nba.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2e14033ca8b7>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation_by_region\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_loss_by_region\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mnba_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-2e14033ca8b7>\u001b[0m in \u001b[0;36mnba_correlation\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnba_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"assets/nba.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"assets/wikipedia_data.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Selecciona todas las filas exepto la ultima, y se indica los índices de las columnas que se van a conservar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'assets/nba.csv'"
          ]
        }
      ],
      "source": [
        "\n",
        "def nba_correlation():\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import scipy.stats as stats\n",
        "    import re\n",
        "\n",
        "    nba_df=pd.read_csv(\"assets/nba.csv\")\n",
        "    cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
        "    cities=cities.iloc[:-1,[0,3,5,6,7,8]] #Selecciona todas las filas exepto la ultima, y se indica los índices de las columnas que se van a conservar\n",
        "\n",
        "    nba_df=nba_df[nba_df[\"year\"] == 2018] #Dejar solo las columnas del 2018\n",
        "    nba_df=nba_df[[\"team\", \"W\", \"L\"]]#Dejar solo las columnas necesarias de NHL\n",
        "    nba_df[\"team\"]=nba_df[\"team\"].str.replace(r\"\\(.*\\)\",\"\").str.replace(r\"\\*\",\"\") #Limpiar el nombre de los equipos. Algunos equipos tienen \"*\" y \"()\" al final\n",
        "\n",
        "    cities[\"NBA\"]=cities[\"NBA\"].str.replace(\"\\[.*\\]\",\"\") #Limpiar el nombre de los equipos en \"cities\" de \"NBA\". Algunos de ellos tienen \"[]\" en el\n",
        "    cities=cities[[\"Metropolitan area\", \"Population (2016 est.)[8]\", \"NBA\"]]\n",
        "    nba_df[\"team_only\"]=nba_df.team.apply(lambda x: x.rsplit(None, 1)[-1])\n",
        "\n",
        "    nba_df.loc[10, \"team_only\"]=\"Knicks Nets\"\n",
        "    nba_df.loc[11, \"team_only\"]=\"Knicks Nets\"\n",
        "    nba_df.loc[24, \"team_only\"]=\"Lakers Clippers\"\n",
        "    nba_df.loc[25, \"team_only\"]=\"Lakers Clippers\"\n",
        "    nba_df.loc[17, \"team_only\"]=\"Trail Blazers\"\n",
        "\n",
        "    cities=cities.rename(columns={'Metropolitan area':'city', 'Population (2016 est.)[8]':'population', 'NBA':'team_only'})#Renombrar las ciudades en un formato mas legible\n",
        "\n",
        "    nba_df.W=nba_df.W.astype(float) #Cambiar el tipo de datos de ganadores y perdedores de str a float\n",
        "    nba_df.L=nba_df.L.astype(float)\n",
        "\n",
        "    nba_df=nba_df.groupby(by=\"team_only\")[\"W\", \"L\"].mean() #Hay 4 equipos con el mismo nombre, vamos a agruparlos y obtener su promedio de los valores win y lose\n",
        "    nba_df=nba_df.reset_index() #Restablecer los indices luego de agruparlos para que puedan ser combinados con cities_df con su columna en común\n",
        "    merged_df=pd.merge(nba_df, cities, on=\"team_only\") #Combinar ambos dataframes con las columnas requeridas de ambos\n",
        "\n",
        "    merged_df[[\"W\", \"L\"]]=merged_df[[\"W\", \"L\"]].astype(float) #Cambiar el tipo de datos de w y l de str a float\n",
        "\n",
        "    merged_df[\"win_lose_ratio\"] = merged_df.W/(merged_df.L+merged_df.W) #Crear la coluumna ratio win/lose ratio = win/lose+win\n",
        "\n",
        "\n",
        "    population_by_region = pd.to_numeric(merged_df[\"population\"],errors=\"coerce\") # pass in metropolitan area population from cities\n",
        "    win_loss_by_region = pd.to_numeric(merged_df[\"win_lose_ratio\"],errors=\"coerce\") # pass in win/loss ratio from nba_df in the same order as cities[\"Metropolitan area\"]\n",
        "\n",
        "    assert len(population_by_region) == len(win_loss_by_region), \"Q2: Your lists must be the same length\"\n",
        "    assert len(population_by_region) == 28, \"Q2: There should be 28 teams being analysed for NBA\"\n",
        "\n",
        "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n",
        "\n",
        "nba_correlation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1a1a5809f675ca033086422007cd73bd",
          "grade": false,
          "grade_id": "cell-96e15e4335df78f4",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "h1vJC0Q73DQu"
      },
      "source": [
        "## Stage 3\n",
        "Win/loss ratio's correlation with the population of the city it is in for the **MLB** using **2018** data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "27e8c0da6c9fa0dffc10488314335b6c",
          "grade": false,
          "grade_id": "cell-33b00fc3f3467b0c",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "EJ2lOORx3DQu",
        "outputId": "18849bfd-e619-49d3-8fbc-316c69e9907d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.15052304487104848"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def mlb_correlation():\n",
        "\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import scipy.stats as stats\n",
        "    import re\n",
        "\n",
        "    mlb_df=pd.read_csv(\"assets/mlb.csv\")\n",
        "    cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
        "    cities=cities.iloc[:-1,[0,3,5,6,7,8]] #Selecciona todas las filas exepto la ultima, y se indica los índices de las columnas que se van a conservar\n",
        "\n",
        "    mlb_df=mlb_df[mlb_df.year==2018] #Dejar solo las columnas del 2018\n",
        "    mlb_df=mlb_df[[\"team\", \"W\", \"L\"]] #Dejar solo las columnas necesarias de NHL\n",
        "    mlb_df[\"team\"] = mlb_df[\"team\"].str.replace(\"\\*$\", \"\", regex=True) #Limpiar el nombre de los equipos. Algunos equipos tienen \"*\" al final\n",
        "    cities[\"MLB\"]=cities[\"MLB\"].replace(r\"\\[.*\\]\", \"\", regex=True) #Limpiar el nombre de los equipos en \"cities\" de \"NHL\". Algunos de ellos tienen \"[]\" en el\n",
        "    cities=cities[['Metropolitan area', 'Population (2016 est.)[8]', 'MLB']] #Eliminar las columnas inecesarias\n",
        "    mlb_df[\"team_only\"] = mlb_df.team.apply(lambda x: x.rsplit(None, 1)[-1]) #En nhl_df los nombres de los equipos están mezclados con los nombres de las ciudades. Cepararlos para obtener los ganadores y perdedores\n",
        "\n",
        "\n",
        "    mlb_df.loc[13, \"team_only\"] = \"Dodgers Angels\" #Algunos equipos tienen mas de una palabra en el nombre. Corregir eso\n",
        "    mlb_df.loc[25, \"team_only\"] = \"Dodgers Angels\"\n",
        "\n",
        "    mlb_df.loc[18, \"team_only\"] = \"Yankees Mets\"\n",
        "    mlb_df.loc[1, \"team_only\"] = \"Yankees Mets\"\n",
        "\n",
        "    mlb_df.loc[11, \"team_only\"] = \"Giants Athletics\"\n",
        "    mlb_df.loc[28, \"team_only\"] = \"Giants Athletics\"\n",
        "\n",
        "    mlb_df.loc[0, \"team_only\"] = \"Red Sox\"\n",
        "    #mlb_df.loc[2, \"team_only\"] = \"Bay Rays\"\n",
        "    mlb_df.loc[3, \"team_only\"] = \"Blue Jays\"\n",
        "\n",
        "    mlb_df.loc[21, \"team_only\"] = \"Cubs White Sox\"\n",
        "    mlb_df.loc[8, \"team_only\"] = \"Cubs White Sox\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    cities=cities.rename(columns={'Metropolitan area':'city', 'Population (2016 est.)[8]':'population', 'MLB':'team_only'})#Renombrar las ciudades en un formato mas legible\n",
        "    #mlb_df=mlb_df[~mlb_df.W.str.contains(\"Division\")]#Quitar las filas inecesarias con el nombre \"Division\" en ellas\n",
        "    mlb_df.W=mlb_df.W.astype(float) #Cambiar el tipo de datos de ganadores y perdedores de str a float\n",
        "    mlb_df.L=mlb_df.L.astype(float)\n",
        "    mlb_df=mlb_df.groupby(by=\"team_only\")[\"W\", \"L\"].mean() #Hay 4 equipos con el mismo nombre, vamos a agruparlos y obtener su promedio de los valores win y lose\n",
        "    mlb_df=mlb_df.reset_index() #Restablecer los indices luego de agruparlos para que puedan ser combinados con cities_df con su columna en común\n",
        "    merged_df=pd.merge(mlb_df, cities, on=\"team_only\") #Combinar ambos dataframes con las columnas requeridas de ambos\n",
        "\n",
        "\n",
        "\n",
        "    merged_df[[\"W\", \"L\"]]=merged_df[[\"W\", \"L\"]].astype(float) #Cambiar el tipo de datos de w y l de str a float\n",
        "\n",
        "\n",
        "    merged_df[\"win_lose_ratio\"] = merged_df.W/(merged_df.L+merged_df.W) #Crear la coluumna ratio win/lose ratio = win/lose+win\n",
        "\n",
        "\n",
        "       # raise NotImplementedError()\n",
        "\n",
        "    population_by_region = pd.to_numeric(merged_df[\"population\"],errors=\"coerce\") # pass in metropolitan area population from cities\n",
        "    win_loss_by_region = pd.to_numeric(merged_df[\"win_lose_ratio\"],errors=\"coerce\") # pass in win/loss ratio from mlb_df in the same order as cities[\"Metropolitan area\"]\n",
        "\n",
        "\n",
        "    assert len(population_by_region) == len(win_loss_by_region), \"Q3: Your lists must be the same length\"\n",
        "    assert len(population_by_region) == 26, \"Q3: There should be 26 teams being analysed for MLB\"\n",
        "    #\n",
        "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n",
        "mlb_correlation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6977a6da9ed6d8b7a0b7e37bbeda709b",
          "grade": false,
          "grade_id": "cell-793df6c04dfb126e",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "B6bmpYJz3DQu"
      },
      "source": [
        "## Stage 4\n",
        "Win/loss ratio's correlation with the population of the city it is in for the **NFL** using **2018** data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c4914ad1e119278ec2bd567c52640b66",
          "grade": false,
          "grade_id": "cell-8ccebc209aeec8d9",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "liP8EE8_3DQv",
        "outputId": "d9a16cd1-987c-4e02-ed71-bedaa693da61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.00492211214934943"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "def nfl_correlation():\n",
        "\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import scipy.stats as stats\n",
        "    import re\n",
        "\n",
        "    nfl_df=pd.read_csv(\"assets/nfl.csv\")\n",
        "    cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
        "    cities=cities.iloc[:-1,[0,3,5,6,7,8]] #Selecciona todas las filas exepto la ultima, y se indica los índices de las columnas que se van a conservar\n",
        "\n",
        "    nfl_df=nfl_df[nfl_df.year==2018] #Dejar solo las columnas del 2018\n",
        "    nfl_df=nfl_df[[\"team\", \"W\", \"L\"]] #Dejar solo las columnas necesarias de NHL\n",
        "    nfl_df[\"team\"] = nfl_df[\"team\"].str.replace(\"\\*$\", \"\", regex=True) #Limpiar el nombre de los equipos. Algunos equipos tienen \"*\" al final\n",
        "    nfl_df[\"team\"] = nfl_df[\"team\"].str.replace(\"\\+$\", \"\", regex=True)\n",
        "    cities[\"NFL\"]=cities[\"NFL\"].replace(r\"\\[.*\\]\", \"\", regex=True) #Limpiar el nombre de los equipos en \"cities\" de \"NHL\". Algunos de ellos tienen \"[]\" en el\n",
        "    cities=cities[['Metropolitan area', 'Population (2016 est.)[8]', 'NFL']] #Eliminar las columnas inecesarias\n",
        "    nfl_df[\"team_only\"] = nfl_df.team.apply(lambda x: x.rsplit(None, 1)[-1]) #En nhl_df los nombres de los equipos están mezclados con los nombres de las ciuda\n",
        "    cities\n",
        "    nfl_df.loc[17, \"team_only\"] = \"Rams Chargers\" #Algunos equipos tienen mas de una palabra en el nombre. Corregir eso\n",
        "    nfl_df.loc[36, \"team_only\"] = \"Rams Chargers\"\n",
        "\n",
        "    nfl_df.loc[24, \"team_only\"] = \"Giants Jets\"\n",
        "    nfl_df.loc[4, \"team_only\"] = \"Giants Jets\"\n",
        "\n",
        "    nfl_df.loc[19, \"team_only\"] = \"49ers Raiders\"\n",
        "    nfl_df.loc[38, \"team_only\"] = \"49ers Raiders\"\n",
        "\n",
        "    cities=cities.rename(columns={'Metropolitan area':'city', 'Population (2016 est.)[8]':'population', 'NFL':'team_only'})#Renombrar las ciudades en un formato mas legible\n",
        "    nfl_df=nfl_df[~nfl_df.team.str.contains(\"AFC\")]#Quitar las filas inecesarias con el nombre \"Division\" en ellas\n",
        "    nfl_df=nfl_df[~nfl_df.team.str.contains(\"NFC\")]#Quitar las filas inecesarias con el nombre \"Division\" en ellas\n",
        "    nfl_df.W=nfl_df.W.astype(float) #Cambiar el tipo de datos de ganadores y perdedores de str a float\n",
        "    nfl_df.L=nfl_df.L.astype(float)\n",
        "    nfl_df=nfl_df.groupby(by=\"team_only\")[\"W\", \"L\"].mean() #Hay 4 equipos con el mismo nombre, vamos a agruparlos y obtener su promedio de los valores win y lose\n",
        "    nfl_df=nfl_df.reset_index() #Restablecer los indices luego de agruparlos para que puedan ser combinados con cities_df con su columna en común\n",
        "    merged_df=pd.merge(nfl_df, cities, on=\"team_only\") #Combinar ambos dataframes con las columnas requeridas de ambos\n",
        "\n",
        "\n",
        "    merged_df[[\"W\", \"L\"]]=merged_df[[\"W\", \"L\"]].astype(float) #Cambiar el tipo de datos de w y l de str a float\n",
        "\n",
        "\n",
        "    merged_df[\"win_lose_ratio\"] = merged_df.W/(merged_df.L+merged_df.W) #Crear la coluumna ratio win/lose ratio = win/lose+win\n",
        "\n",
        "\n",
        "    population_by_region = pd.to_numeric(merged_df[\"population\"],errors=\"coerce\") # pass in metropolitan area population from cities\n",
        "    win_loss_by_region = pd.to_numeric(merged_df[\"win_lose_ratio\"],errors=\"coerce\") # pass in win/loss ratio from nfl_df in the same order as cities[\"Metropolitan area\"]\n",
        "\n",
        "    assert len(population_by_region) == len(win_loss_by_region), \"Q4: Your lists must be the same length\"\n",
        "    assert len(population_by_region) == 29, \"Q4: There should be 29 teams being analysed for NFL\"\n",
        "\n",
        "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n",
        "\n",
        "nfl_correlation()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}